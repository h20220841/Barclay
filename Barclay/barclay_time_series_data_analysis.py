# -*- coding: utf-8 -*-
"""Barclay Time Series Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zvEDrD9j9f5iNrBokk4j-rDvk6okPHP7

**Data Project - Stock Market Analysis**

In this notebook, we will discover and explore data from the stock market, particularly some technology stocks (Barclay, Deutsche Bank, Bank of America, and Credit Suiess).I will use **yfinance** to get stock information, and visualize different aspects of it using Seaborn and Matplotlib. Firstly I will look at a few ways of analyzing the risk of a stock, based on its previous performance history hen we will also be predicting future stock prices through a **Long Short Term Memory (LSTM)** method!

We'll be answering the following questions along the way:

1.) What was the change in price of the stock over time?

2.) What was the daily return of the stock on average?

3.) What was the moving average of the various stocks?

4.) What was the correlation between different stocks'?

5.) How much value do we put at risk by investing in a particular stock?

6.) How can we attempt to predict future stock behavior? (Predicting the closing price stock price of **Barclay**  using **LSTM**)

**Getting the Data**

```
The first step is to get the data and load it to memory.
We will get our stock data from the Yahoo Finance website.
Yahoo Finance is a rich resource of financial market data and tools to find compelling investments.
To get the data from Yahoo Finance, we will be using yfinance library which offers a threaded and
Pythonic way to download market data from Yahoo.
```

**Download the Data set**
"""

#install import library
!pip install -q yfinance

# Commented out IPython magic to ensure Python compatibility.
#import essential library for analysis
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')
plt.style.use("fivethirtyeight")
# %matplotlib inline

# For reading stock data from yahoo
from pandas_datareader.data import DataReader
import yfinance as yf
from pandas_datareader import data as pdr

yf.pdr_override()

# For time stamps
from datetime import datetime

#The bank stock we will use for this analysis
bank_list = ['BCS','DB','BAC','CS']

# BCS--> BARCLAY, DB-->Deutsche Bank , BAC-->Bank of America, CS--> Credit Suiess

#Set up End and Start times for data grab
bank_list = ['BCS','DB','BAC','CS']

end = datetime.now()
start = datetime(end.year - 1, end.month, end.day)

#Download the dataset and make a data frame
for stock in bank_list:
  globals()[stock] = yf.download(stock,start,end)
#Using globals() is a sloppy way of setting the DataFrame names, but it's simple.

company_list = [BCS,DB,BAC,CS]
company_name = ['BARCLAY','Deutsche Bank','BANK OF AMERICA','CREDIT SUIESS']

for company, com_name in zip(company_list,company_name):
  company['company_name'] = com_name

df = pd.concat(company_list, axis=0)
df.tail(10)

"""So, we have downloaded the data set which have the columns name as:

Date,  Open,
 High,  Low,  Close,  Adj Close,
  Volume, Company name

**Descriptive Statistics about the Data**

**.describe()** generates descriptive statistics. Descriptive statistics include those that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN values.

Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types. The output will vary depending on what is provided.

__1.) What was the change in price of the stock over time?__
"""

#Summary Stats of Barclay stock prices
BCS.describe()

"""We have only 251 records in one year because weekends are not included in the data."""

#Information about the barclay(BCS) data
BCS.info()

"""**Closing Price**

* The closing price is the price at which
the stock is traded during the regular day.

* A stock closing price is the standard benchmark used by investors to track its performance over time.
"""

#Let's see a historical view of the closing price
plt.figure(figsize=(15,10))
plt.subplots_adjust(top=1.25, bottom=1.2)

for i, company in enumerate(company_list,1):
  plt.subplot(2,2,i)
  company['Adj Close'].plot()
  plt.ylabel('Adj Close')
  plt.xlabel(None)
  plt.title(f"Closing Price of {bank_list[i - 1]}")

plt.tight_layout()

"""**Volume of Sales**

* Volume is the amount of an asset or security that changes hands over some period of time, often over the course of a day.

* For instance, the stock trading volume would refer to the number of shares of security traded between its daily open and close.
"""

#Now let's plot the total volume of stock being traded each day
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 10))
plt.subplots_adjust(top=1.25, bottom=1.2)

num_subplots = len(company_list)  # Total number of subplots based on the number of companies

for i, company in enumerate(company_list):
  # The enumerate() function is used to iterate over a sequence
    plt.subplot(2, 2, i + 1)  # Increment i by 1 to avoid the ValueError
    company['Volume'].plot()
    plt.ylabel('Volume')
    plt.xlabel(None)
    plt.title(f"Sales Volume for {bank_list[i]}")  # Use i instead of i - 1 for bank_list

plt.tight_layout()
plt.show()

"""Now that we have seen the visualizations for the closing price and the volume traded each day, let's go for calculating the moving average fpr the stock.

**2.) What was the moving average of the various stocks?**

* The **moving average (MA)** is a simple technical analysis tool that smooths out price data by creating a constantly updated average price.

* The average is taken over a specific period of time, like 10 days, 20 minutes, 30 weeks, or any time period the trader chooses.
"""

ma_day = [10,20,50]

for ma in ma_day:
  for company in company_list:
    column_name = f"MA for {ma} days"
    company[column_name]  = company['Adj Close'].rolling(ma).mean()


# Create the subplot grid
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))

# Plot data for each company in a separate subplot
BCS[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])
axes[0,0].set_title('Barclay')

DB[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])
axes[0,1].set_title('Deutsche Bank')

BAC[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])
axes[1,0].set_title('Bank of America')

CS[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])
axes[1,1].set_title('Credit Suiess')

fig.tight_layout()

"""We see in the graph that the best values to measure the moving average are 10 and 20 days because we still capture trends in the data without noise.

**3.) What was the daily return of the stock on average?**

We're now going to analyze the risk of the stock. In order to do so we'll need to take a closer look at the daily changes of the stock, and not just its absolute value.
___
"""

#We will use pct_change to find the percentage change for each day stock price of data set
for company in company_list:
  company['Daily Return'] = company['Adj Close'].pct_change()

#Then we will plot the daily return percentage
# Create the subplot grid
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))

BCS['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')
axes[0,0].set_title('Barclay')

DB['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')
axes[0,1].set_title('Deutsche Bank')

BAC['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')
axes[1,0].set_title('Bank of America')

CS['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')
axes[1,1].set_title('Credit Suiess')

fig.tight_layout()

"""Now let's get an overall look at the **average** daily return using a histogram. We'll use **seaborn** to create a **histogram** plot."""

#Plot histogram for the data set
plt.figure(figsize=(12, 9))

for i, company in enumerate(company_list, 1):
  plt.subplot(2,2,i)
  company['Daily Return'].hist(bins=50)
  plt.xlabel('Daily Return')
  plt.ylabel('Counts')
  plt.title(f'{company_name[i - 1]}')

plt.tight_layout()

"""**4.) What was the correlation between different stocks closing prices?**

* **Correlation** is a statistic that measures the degree to which two variables move in relation to each other which has a value that must fall between **-1.0 and +1.0.**

* **Correlation** measures association, but doesn’t show if x causes y or vice versa — or if the association is caused by a third factor.

Now we will analyze the returns of all the stocks with [close] column for each of the stock dataframes.
"""

#Now make a dataframe for closing price of all the bank list data set into one DataFrame
closing_df = pdr.get_data_yahoo(bank_list, start=start, end=end)['Adj Close']

#Make a new bank returns DataFrame
bank_rets = closing_df.pct_change()
bank_rets.head()

"""Now we can compare the daily percentage return of two stocks to check how correlated."""

#We can simply cal  pairplot on our dataframe for an automatic visual analysis of all the comparisons
sns.pairplot(bank_rets, kind='reg')

"""From this above plot, we are not able to clearly draw any insight. let's draw indivisual pair plot for better understanding."""

#Comparing barclay to itself
sns.jointplot(x='BCS', y='BCS', data=bank_rets, kind='scatter', color='seagreen')

"""Graph shows a perfectly linear relationship for barclay itself."""

# we will use joinplot to compare the daily returns of barclay and bank of america
sns.jointplot(x='BCS', y='BAC', data=bank_rets, kind='scatter')

"""So now we can see that between Barclay and Bank of Ameica are somehow (and positivley) correlated with each other and a linear relationship bewteen them exist."""

# we will use joinplot to compare the daily returns of barclay and cresit suiess
sns.jointplot(x='BCS', y='CS', data=bank_rets, kind='scatter')

# we will use joinplot to compare the daily returns of barclay and Deutsche Bank
sns.jointplot(x='BCS', y='DB', data=bank_rets, kind='scatter')

"""Here from the above graph, you can see there is positive correlation between the 'BCS' and 'DB' bank.

To see the actual numerical correlation values, we can draw a heat map for stock daily return values.
"""

#Plot a heat map for the better view of correlation between them
plt.figure(figsize=(12,10))

plt.subplot(2,2,1)
sns.heatmap(bank_rets.corr(), annot=True, cmap='summer')
plt.title('Correlation of stock returns')

plt.subplot(2,2,2)
sns.heatmap(closing_df.corr(), annot=True, cmap='summer')
plt.title('Correlation of stock closing price')

"""* We can see from the heat map value that in case of stock returns between **Barclay** and **Deutschy bank** is highly correlated **(0.72)** value as compare to the other stocks.

* Similarly in case of cosing stock price there is strong correlation value **(0.76)** between the **Deutschy bank** and **Barclay** as compare to other.

**5.) How much value do we put at risk by investing in a particular stock?**

There are many ways we can quantify risk, one of the most basic ways using the information we've gathered on daily percentage returns is by comparing the expected return with the standard deviation of the daily returns.
"""

rets = bank_rets.dropna()

area = np.pi * 20

plt.figure(figsize=(10, 8))
plt.scatter(rets.mean(), rets.std(), s=area)
plt.xlabel('Expected return')
plt.ylabel('Risk')

for label, x, y in zip(rets.columns, rets.mean(), rets.std()):
    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',
                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))

"""From above graph plot we can see that the following results:

* **CS** = Risk--> High, Expected Return--> negative

* **BAC** = Risk--> Low, Expected Return--> Low (closed to zero)

* **BCS** = Risk--> greater than low, Expected Return--> close to 0.1%

* **DB** = Risk--> greater than low, Expected Return--> close to 0.2% better than other stocks.

**6.) Predicting the closing price stock price of Barclay:**
"""

#Get the stock data of Barclay
df = pdr.get_data_yahoo('BCS', start='2013-01-01', end=datetime.now())
df.head()

df.shape

#Plot the time series data set
plt.figure(figsize=(16,6))
plt.title('Close Price History')
plt.plot(df['Close'])
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.show()

# Create a new dataframe with only the 'close' column
data = df.filter(['Close'])

#Convert the dataframe to a numpy array
dataset = data.values

#Get the number of rows to train the model
training_data_len = int(np.ceil( len(dataset) * .95))
#np.ceil(): It ensures that the calculated training data length is always rounded up to the nearest whole number.

training_data_len

#Scale the data
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

scaled_data

# Create the training data set
# Create the scaled training data set
train_data = scaled_data[0:int(training_data_len), :]

# Split the data into x_train and y_train data sets
x_train = []
y_train = []

for i in range(60, len(train_data)):
#It starts from index 60 because we need at least 60 data points to create a sequence of past data points for prediction.
  x_train.append(train_data[i-60:i, 0])
  y_train.append(train_data[i, 0])
  if i<= 61:
    print(x_train)
    print(y_train)
    print()

# Convert the x_train and y_train to numpy arrays
x_train, y_train = np.array(x_train), np.array(y_train)

# Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

#Now make LSTM model
from keras.models import Sequential
from keras.layers import Dense, LSTM

# Build the  LSTM (Long Short-Term Memory) model
#The LSTM model is a type of recurrent neural network (RNN) that is well-suited for sequence data, such as time series data.
model = Sequential()
model.add(LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(64, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))


#Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(x_train, y_train, batch_size=1, epochs=1)

#Creating the testing data set

test_data = scaled_data[training_data_len - 60:, :]

# Create the data sets x_test and y_test
x_test = []
y_test = dataset[training_data_len:, :]

for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i, 0])

#Convert the data to numpy array
x_test = np.array(x_test)

# Reshape the data
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))

# Get the models predicted price values
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# Get the root mean squarred error (RMSE)
rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))

rmse

# Plot the data
train = data[:training_data_len]
valid = data[training_data_len:]
valid['Predictions'] = predictions
# Visualize the data
plt.figure(figsize=(16,6))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Price USD ($)', fontsize=18)
plt.plot(train['Close'])
plt.plot(valid[['Close', 'Predictions']])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

#Show the valid and predicted prices
valid

"""References:

* https://www.machinelearningplus.com/time-series/time-series-analysis-python/

* https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/

* https://www.kaggle.com/code/faressayah/stock-market-analysis-prediction-using-lstm

* https://www.kaggle.com/code/pierpaolo28/stock-market-analysis-and-time-series-prediction

"""

